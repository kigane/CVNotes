{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from einops import rearrange, reduce, repeat\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_eq(tensor, shape):\n",
    "    return tensor.shape == torch.Size(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ViT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### patch embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 196, 768])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from argparse import Namespace\n",
    "args = {\n",
    "    'embed_dim': 768,\n",
    "    'patch_size': 16,\n",
    "    'num_heads': 8\n",
    "}\n",
    "args = Namespace(**args)\n",
    "x = torch.rand(1, 3, 224, 224)\n",
    "# patch embedding\n",
    "proj = nn.Conv2d(3, args.embed_dim, # 16x16x3=768, 16x14=224, 14x14=196\n",
    "    kernel_size=args.patch_size,\n",
    "    stride=args.patch_size)\n",
    "ln = nn.LayerNorm((196, 768))\n",
    "x = rearrange(proj(x), 'b d h w -> b (h w) d') # 一张图片变成196个768维的token\n",
    "x = ln(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MHSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 196, 2304])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 8, 196, 96])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_dim = args.embed_dim // args.num_heads\n",
    "scale = head_dim ** -0.5 # 1/sqrt(d_k)\n",
    "qkv = nn.Linear(args.embed_dim, args.embed_dim*3)\n",
    "attn_drop = nn.Dropout(0.5)\n",
    "proj_fuse = nn.Linear(args.embed_dim, args.embed_dim)\n",
    "fuse_drop = nn.Dropout(0.5)\n",
    "\n",
    "# input [B N D] = [1, 196, 768]\n",
    "residual = x\n",
    "x = qkv(x)\n",
    "print(x.shape)\n",
    "x = rearrange(x, 'b n (m h d) -> m b h n d', m=3, h=args.num_heads)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 196, 96]),\n",
       " torch.Size([1, 8, 196, 96]),\n",
       " torch.Size([1, 8, 196, 96]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q, k, v = torch.unbind(x, dim=0)\n",
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = torch.einsum('bhik,bhjk->bhij', q, k) * scale # QK^T/sqrt(d_k)\n",
    "assert shape_eq(attn, [1, 8, 196, 196])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = attn_drop(torch.softmax(attn, dim=-1)) # 归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.einsum('bhik,bhkj->bhij', attn, v) # softmax(QK^T/sqrt(d_k)) @ v\n",
    "assert shape_eq(v, [1, 8, 196, 96])\n",
    "v = rearrange(v, 'b h n d -> b n (h d)')\n",
    "assert shape_eq(v, [1, 196, 768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多头融合\n",
    "x = fuse_drop(proj_fuse(v))\n",
    "assert shape_eq(x, [1, 196, 768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x + residual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input [B N D] = [1, 196, 768]\n",
    "mlp = nn.Sequential(\n",
    "    nn.Linear(args.embed_dim, args.embed_dim*2),\n",
    "    nn.GELU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(args.embed_dim*2, args.embed_dim),\n",
    "    nn.Dropout(0.5)\n",
    ")\n",
    "\n",
    "residual = x\n",
    "x = mlp(x)\n",
    "x = x + residual\n",
    "assert shape_eq(x, [1, 196, 768])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Swin transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbed(nn.Module):\n",
    "    \"\"\"\n",
    "    2D Image to Patch Embedding\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "        patch_size=4, # 下采样倍数\n",
    "        in_c=3, \n",
    "        embed_dim=96, # C\n",
    "        norm_layer=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        patch_size = (patch_size, patch_size)\n",
    "        self.patch_size = patch_size\n",
    "        self.in_chans = in_c\n",
    "        self.embed_dim = embed_dim\n",
    "        # Patch partition & Linear projection\n",
    "        self.proj = nn.Conv2d(in_c, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.norm = norm_layer(embed_dim) if norm_layer else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, _, H, W = x.shape\n",
    "\n",
    "        # padding\n",
    "        # 如果输入图片的H，W不是patch_size的整数倍，需要进行padding\n",
    "        pad_input = (H % self.patch_size[0] != 0) or (W % self.patch_size[1] != 0)\n",
    "        if pad_input:\n",
    "            # to pad the last 3 dimensions,\n",
    "            # (W_left, W_right, H_top,H_bottom, C_front, C_back)\n",
    "            x = F.pad(x, (0, self.patch_size[1] - W % self.patch_size[1],\n",
    "                          0, self.patch_size[0] - H % self.patch_size[0],\n",
    "                          0, 0))\n",
    "\n",
    "        # 下采样patch_size倍\n",
    "        x = self.proj(x)\n",
    "        _, _, H, W = x.shape\n",
    "        # flatten: [B, C, H, W] -> [B, C, HW]\n",
    "        # transpose: [B, C, HW] -> [B, HW, C]\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        x = self.norm(x)\n",
    "        return x, H, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 56)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_proj = PatchEmbed(4, 3, 96)\n",
    "x = torch.rand(1, 3, 224, 224)\n",
    "tokens, H, W = patch_proj(x)\n",
    "assert shape_eq(tokens, [1, 56*56,96])\n",
    "H, W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patch Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchMerging(nn.Module):\n",
    "    r\"\"\" Patch Merging Layer.\n",
    "    Args:\n",
    "        dim (int): Number of input channels.\n",
    "        norm_layer (nn.Module, optional): Normalization layer.  Default: nn.LayerNorm\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim, norm_layer=nn.LayerNorm):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.reduction = nn.Linear(4 * dim, 2 * dim, bias=False)\n",
    "        self.norm = norm_layer(4 * dim)\n",
    "\n",
    "    def forward(self, x, H, W):\n",
    "        \"\"\"\n",
    "        x: B, H*W, C\n",
    "        \"\"\"\n",
    "        B, L, C = x.shape\n",
    "        assert L == H * W, \"input feature has wrong size\"\n",
    "\n",
    "        x = x.view(B, H, W, C)\n",
    "\n",
    "        # padding\n",
    "        # 如果输入feature map的H，W不是2的整数倍，需要进行padding\n",
    "        pad_input = (H % 2 == 1) or (W % 2 == 1)\n",
    "        if pad_input:\n",
    "            # to pad the last 3 dimensions, starting from the last dimension and moving forward.\n",
    "            # (C_front, C_back, W_left, W_right, H_top, H_bottom)\n",
    "            # 注意这里的Tensor通道是[B, H, W, C]，所以会和官方文档有些不同\n",
    "            x = F.pad(x, (0, 0, 0, W % 2, 0, H % 2))\n",
    "\n",
    "        x0 = x[:, 0::2, 0::2, :]  # [B, H/2, W/2, C]\n",
    "        x1 = x[:, 1::2, 0::2, :]  # [B, H/2, W/2, C]\n",
    "        x2 = x[:, 0::2, 1::2, :]  # [B, H/2, W/2, C]\n",
    "        x3 = x[:, 1::2, 1::2, :]  # [B, H/2, W/2, C]\n",
    "        x = torch.cat([x0, x1, x2, x3], -1)  # [B, H/2, W/2, 4*C]\n",
    "        x = x.view(B, -1, 4 * C)  # [B, H/2*W/2, 4*C]\n",
    "\n",
    "        x = self.norm(x)\n",
    "        x = self.reduction(x)  # [B, H/2*W/2, 2*C]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([1, 3136, 96])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784, 384])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm = PatchMerging(96)\n",
    "x = tokens # [1, 56*56, 96]\n",
    "print(f'input shape: {x.shape}')\n",
    "H=W=56\n",
    "x = x.view(1, H, W, 96)\n",
    "x0 = x[:, 0::2, 0::2, :]  # [B, H/2, W/2, C]\n",
    "x1 = x[:, 1::2, 0::2, :]  # [B, H/2, W/2, C]\n",
    "x2 = x[:, 0::2, 1::2, :]  # [B, H/2, W/2, C]\n",
    "x3 = x[:, 1::2, 1::2, :]  # [B, H/2, W/2, C]\n",
    "x = torch.cat([x0, x1, x2, x3], -1)  # [B, H/2, W/2, 4*C]\n",
    "x = x.view(1, -1, 4 * 96)  # [B, H/2*W/2, 4*C]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784, 384])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = rearrange(tokens, 'b (h w) d -> b h w d', h=56)\n",
    "z = rearrange(z, 'b (p1 h) (p2 w) d -> b (h w) (p1 p2 d)', p1=2, p2=2)\n",
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ True,  True,  True,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         ...,\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ..., False, False, False],\n",
       "         [False, False, False,  ...,  True,  True,  True]]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z == x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784, 192])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pm(tokens, 56, 56)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  4,  8, 12],\n",
       "         [ 1,  5,  9, 13]],\n",
       "\n",
       "        [[ 2,  6, 10, 14],\n",
       "         [ 3,  7, 11, 15]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(16)\n",
    "rearrange(x, '(p1 p2 h w) -> h w (p1 p2)', p1=2, p2=2, h=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "448c60747e7ce04bfef225ceb0b037f93919a769940cfe3c5278db7a5ae07e34"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
